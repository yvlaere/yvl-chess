{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec5d7453",
   "metadata": {},
   "source": [
    "# NNUE training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26821225",
   "metadata": {},
   "source": [
    "## Model architecture\n",
    "\n",
    "Current model architecture is a sparse, binary array of length 768. Each element of the array represents a possible combination of piece type (6), piece_color (2) and position (64) (6*2*64 = 768).  \n",
    "\n",
    "The fully connected feedfoward network has 3 hidden layers: 768 -> 8, 8 -> 8 and 8 -> 1.\n",
    "\n",
    "The output is a single scalar.\n",
    "\n",
    "Currently used training data: https://www.kaggle.com/competitions/train-your-own-stockfish-nnue/data\n",
    "\n",
    "Great source on NNUE: https://official-stockfish.github.io/docs/nnue-pytorch-wiki/docs/nnue.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bead68bd",
   "metadata": {},
   "source": [
    "## Input data\n",
    "### Load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3c33597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 FEN  Evaluation\n",
      "0  r1b2rk1/ppp2pbp/3q1np1/n3p1B1/2B5/1Q3N2/PP1N1P...        -135\n",
      "1  8/1pp2p2/6k1/4P2p/p1PR1K1P/2r2P2/6P1/8 w - - 0 33         -57\n",
      "2  r2qk1nr/1b3pbp/n3p1p1/1pp1P3/p2PN3/2P2N2/PPB3P...         541\n",
      "3  2b2rk1/5pp1/p2q1n1p/P2pn3/3N4/3BP1B1/2Q2PPP/Rr...         163\n",
      "4  r2qkb1r/ppp2ppb/2n1p3/3n2PQ/3Pp3/2P4P/PP6/RNB1...        -332\n",
      "18.06853701380683\n",
      "619.097853227714\n",
      "-6462\n",
      "7462\n",
      "14.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "input_path = '/home/yvlaere/projects/yvl-chess/NNUE_training/training_data/train.csv'\n",
    "\n",
    "training_df = pd.read_csv(input_path)\n",
    "\n",
    "print(training_df.head())\n",
    "\n",
    "print(np.mean(training_df['Evaluation']))\n",
    "print(np.std(training_df['Evaluation']))\n",
    "print(np.min(training_df['Evaluation']))\n",
    "print(np.max(training_df['Evaluation']))\n",
    "print(np.median(training_df['Evaluation']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ea1c61",
   "metadata": {},
   "source": [
    "### Turn FEN into input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08c3d358",
   "metadata": {},
   "outputs": [],
   "source": [
    "piece_dict = {'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5, 'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11}\n",
    "\n",
    "def FEN_to_input(fen):\n",
    "    \"\"\"\n",
    "    Convert a FEN string to an NNUE input vector.\n",
    "    \"\"\"\n",
    "    # Split the FEN string into its components\n",
    "    sub_FEN = fen.split(' ')\n",
    "    board = sub_FEN[0]\n",
    "    ranks = board.split('/')\n",
    "\n",
    "    # Convert the board to a 1D boolean array\n",
    "    # in the chess engine, position 0 corresponds to a1, so the ranks in the FEN string will need to be reversed\n",
    "    input_layer = np.zeros(768, dtype = np.float32)\n",
    "    position = 0\n",
    "    for rank in ranks[::-1]:\n",
    "        for char in rank:\n",
    "            if char.isdigit():\n",
    "                position += int(char)\n",
    "            else:\n",
    "                input_layer[position*piece_dict[char]] = 1\n",
    "\n",
    "    return input_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f7bcca",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#print(FEN_to_input(training_df['FEN'][0]))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNNUE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNNUE, self).__init__()\n",
    "        # three fully connected layers\n",
    "        self.fc1 = nn.Linear(768, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 256)\n",
    "        self.fc3 = nn.Linear(256, 64)\n",
    "        self.fc4 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.clamp(self.fc1(x), min = 0, max = 1)\n",
    "        x = torch.clamp(self.fc2(x), min = 0, max = 1)\n",
    "        x = torch.clamp(self.fc3(x), min = 0, max = 1)\n",
    "        x = self.fc4(x)  # output can be raw score\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fe72d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general information on data\n",
    "input_data = np.array([FEN_to_input(fen) for fen in training_df['FEN'].values])\n",
    "output_data = np.array(training_df['Evaluation'].values)\n",
    "print(input_data.shape)\n",
    "print(output_data.shape)\n",
    "\n",
    "#1 979 383 entries\n",
    "# if converted to torch tensors, it becomes too large for the RAM (bool -> float32)\n",
    "# so it needs to be fed in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3a6998",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import IterableDataset\n",
    "\n",
    "def get_evaluation(item):\n",
    "    if item['mate'] is not None:\n",
    "        # Assign a high positive or negative value based on the side to move\n",
    "        # Assuming positive for white mates, negative for black mates\n",
    "        return torch.tensor(10000.0 if item['mate'] > 0 else -10000.0, dtype=torch.float32)\n",
    "    elif item['cp'] is not None:\n",
    "        return torch.tensor(item['cp'], dtype=torch.float32)\n",
    "\n",
    "class ChessEvalDataset(IterableDataset):\n",
    "    def __init__(self, hf_dataset):\n",
    "        self.dataset = hf_dataset\n",
    "\n",
    "    def __iter__(self):\n",
    "        for item in self.dataset:\n",
    "            # Example: assuming \"fen\" and \"eval\" are keys\n",
    "            x = torch.tensor(FEN_to_input(item['fen']))       # Convert FEN to tensor\n",
    "            y = get_evaluation(item)  # Evaluation score\n",
    "            yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43af705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, np_input, np_output):\n",
    "        self.input = np_input\n",
    "        self.output = np_output\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.input.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # get one data point\n",
    "        np_x = self.input[idx]\n",
    "        np_y = self.output[idx]\n",
    "\n",
    "        # convert to torch tensors\n",
    "        x = torch.tensor(np_x, dtype=torch.float32)\n",
    "        y = torch.tensor(np_y, dtype=torch.float32)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458f0eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yvlaere/projects/yvl-chess/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# tranport data to torch tensors\n",
    "input_data = np.array([FEN_to_input(fen) for fen in training_df['FEN'].values])\n",
    "output_data = np.array(training_df['Evaluation'].values)\n",
    "#dataset = MyDataset(input_data, output_data)\n",
    "#loader = DataLoader(dataset, batch_size = 2048, shuffle = True, num_workers = 4, pin_memory = True)\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "hf_dataset = load_dataset(\"Lichess/chess-position-evaluations\", split=\"train\", streaming=True)\n",
    "dataset = ChessEvalDataset(hf_dataset)\n",
    "loader = DataLoader(dataset, batch_size = 2048, num_workers = 4, pin_memory = True)\n",
    "\n",
    "# about 2.4G VRAM available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ba10ff",
   "metadata": {},
   "source": [
    "https://talkchess.com/viewtopic.php?start=60&t=75724"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5bc53e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype, but got Bool and Float",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     21\u001b[39m batch_x = batch_x.to(device, non_blocking = \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     22\u001b[39m batch_y = batch_y.to(device, non_blocking = \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m pred = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m)\u001b[49m.squeeze(\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# remove the last dimension\u001b[39;00m\n\u001b[32m     24\u001b[39m loss = criterion(pred, batch_y)\n\u001b[32m     26\u001b[39m optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/yvl-chess/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/yvl-chess/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mSimpleNNUE.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     x = torch.clamp(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mmin\u001b[39m = \u001b[32m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m = \u001b[32m1\u001b[39m)\n\u001b[32m     17\u001b[39m     x = torch.clamp(\u001b[38;5;28mself\u001b[39m.fc2(x), \u001b[38;5;28mmin\u001b[39m = \u001b[32m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m = \u001b[32m1\u001b[39m)\n\u001b[32m     18\u001b[39m     x = torch.clamp(\u001b[38;5;28mself\u001b[39m.fc3(x), \u001b[38;5;28mmin\u001b[39m = \u001b[32m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m = \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/yvl-chess/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/yvl-chess/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/yvl-chess/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 must have the same dtype, but got Bool and Float"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "nr_epochs = 500\n",
    "model = SimpleNNUE().to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "total_size = 581582778\n",
    "batch_size = 2048\n",
    "steps_per_epoch = total_size // batch_size\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=1e-3, \n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=nr_epochs, pct_start=0.3, \n",
    "    anneal_strategy='cos'\n",
    ")\n",
    "criterion = nn.MSELoss()\n",
    "MAE_loss = nn.L1Loss()\n",
    "lowest_MAE = 10000\n",
    "\n",
    "for epoch in range(nr_epochs):\n",
    "    for batch_x, batch_y in loader:\n",
    "        # move data to GPU\n",
    "        batch_x = batch_x.to(device, non_blocking = True)\n",
    "        batch_y = batch_y.to(device, non_blocking = True)\n",
    "        pred = model(batch_x).squeeze(1)  # remove the last dimension\n",
    "        loss = criterion(pred, batch_y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # calculate MAE\n",
    "        MAE = MAE_loss(pred, batch_y)\n",
    "        if MAE < lowest_MAE:\n",
    "            lowest_MAE = MAE\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(f\"New best model saved with MAE: {lowest_MAE.item():.4f}\")\n",
    "        \n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "    print(f\"Epoch {epoch+1}, MAE: {MAE.item():.4f}, lowest MAE: {lowest_MAE:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba51dfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 17/17 [41:16<00:00, 145.70s/files]\n",
      "Generating train split:   3%|▎         | 18453000/581582778 [01:08<47:21:38, 3302.85 examples/s] "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"Lichess/chess-position-evaluations\", split=\"train\")\n",
    "\n",
    "dataset.save_to_disk(\"chess_position_evaluations\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
