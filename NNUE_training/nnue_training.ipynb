{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec5d7453",
   "metadata": {},
   "source": [
    "# NNUE training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26821225",
   "metadata": {},
   "source": [
    "Great source on NNUE: https://official-stockfish.github.io/docs/nnue-pytorch-wiki/docs/nnue.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bead68bd",
   "metadata": {},
   "source": [
    "## Input data\n",
    "\n",
    "Stockfish has a lot of data available for NNUE training in the .binpack format. They have a repo for training NNUEs (nnue-pytorch) that enables efficient dataloading with this format. I don't want to use nnue-pytorch, i want to make my own NNUE training setup.\n",
    "\n",
    "The nnue-pytorch repo also has information on training datasets for NNUEs: https://github.com/official-stockfish/nnue-pytorch/wiki/Training-datasets. They explain how to make your own dataset and link some of the datasets they generated. I will use some of this data, because generating the data myself would be too time-consuming on my hardware.\n",
    "\n",
    "Currently using training data: test80-2024-01-jan-2tb7p.min-v2.v6.binpack.zst from https://huggingface.co/datasets/linrock/test80-2024/tree/main\n",
    "\n",
    "This file contains billions of positions with evaluations in the .binpack format. The stockfish tools branch has a tool to covert the .binpack data into .plain data (https://github.com/official-stockfish/Stockfish/blob/tools/docs/convert.md). I used this tool and stored the first 200M evaluated positions.\n",
    "\n",
    "### Load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b3ca347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ea1c61",
   "metadata": {},
   "source": [
    "### Turn FEN into input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08c3d358",
   "metadata": {},
   "outputs": [],
   "source": [
    "piece_dict = {'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5, 'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11}\n",
    "\n",
    "def FEN_to_input(fen):\n",
    "    \"\"\"\n",
    "    Convert a FEN string to an NNUE input vector.\n",
    "    \"\"\"\n",
    "    # Split the FEN string into its components\n",
    "    sub_FEN = fen.split(' ')\n",
    "    board = sub_FEN[0]\n",
    "    ranks = board.split('/')\n",
    "\n",
    "    # Convert the board to a 1D boolean array\n",
    "    # in the chess engine, position 0 corresponds to a1, so the ranks in the FEN string will need to be reversed\n",
    "    input_layer = np.zeros(768, dtype = np.float32)\n",
    "    position = 0\n",
    "    for rank in ranks[::-1]:\n",
    "        for char in rank:\n",
    "            if char.isdigit():\n",
    "                position += int(char)\n",
    "            else:\n",
    "                input_layer[position*piece_dict[char]] = 1\n",
    "\n",
    "    return torch.tensor(input_layer, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429c0263",
   "metadata": {},
   "source": [
    "## Model architecture\n",
    "\n",
    "Input: a sparse, binary array of length 768. Each element of the array represents a possible combination of piece type (6), piece_color (2) and position (64) (6*2*64 = 768).\n",
    "\n",
    "\n",
    "\n",
    "The fully connected feedfoward network has 4 hidden layers: 768 -> 1024, 1024 -> 8, 8 -> 32 and 32 -> 1.\n",
    "\n",
    "The output is a single scalar.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f7bcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNNUE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNNUE, self).__init__()\n",
    "        # three fully connected layers\n",
    "        self.fc1 = nn.Linear(768, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 8)\n",
    "        self.fc3 = nn.Linear(8, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.clamp(self.fc1(x), min = 0, max = 1)\n",
    "        x = torch.clamp(self.fc2(x), min = 0, max = 1)\n",
    "        x = torch.clamp(self.fc3(x), min = 0, max = 1)\n",
    "        x = self.fc4(x)  # output can be raw score\n",
    "        return x.float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "485a5629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import torch\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "\n",
    "class CsvFenScoreDataset(IterableDataset):\n",
    "    def __init__(self, csv_path, shuffle_buffer=0):\n",
    "        \"\"\"\n",
    "        csv_path: path to CSV file with two columns: fen, score\n",
    "        fen_to_tensor: function(str) -> torch.Tensor\n",
    "        shuffle_buffer: size of in-memory shuffle buffer; 0 = no shuffle\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.csv_path = csv_path\n",
    "        self.shuffle_buffer = shuffle_buffer\n",
    "\n",
    "    def _row_stream(self):\n",
    "        \"\"\"\n",
    "        Generator that yields (fen, score) tuples from the CSV file.\n",
    "        \"\"\"\n",
    "        with open(self.csv_path, newline='') as csvfile:\n",
    "            reader = csv.reader(csvfile)\n",
    "            for row in reader:\n",
    "                if not row or row[0].startswith('#'):\n",
    "                    continue\n",
    "                fen, score = FEN_to_input(row[0].strip()), row[1].strip()\n",
    "                yield fen, torch.tensor(float(score), dtype=torch.float32)\n",
    "\n",
    "    def __iter__(self):\n",
    "        stream = self._row_stream()\n",
    "        if self.shuffle_buffer > 1:\n",
    "            # reservoir-style shuffle buffer\n",
    "            buf = []\n",
    "            for fen, score in stream:\n",
    "                buf.append((fen, score))\n",
    "                if len(buf) >= self.shuffle_buffer:\n",
    "                    idx = torch.randint(len(buf), (1,)).item()\n",
    "                    yield buf.pop(idx)\n",
    "            # drain remaining buffer\n",
    "            while buf:\n",
    "                idx = torch.randint(len(buf), (1,)).item()\n",
    "                yield buf.pop(idx)\n",
    "        else:\n",
    "            for fen, score in stream:\n",
    "                yield fen, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "458f0eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# tranport data to torch tensors\n",
    "#input_data = np.array([FEN_to_input(fen) for fen in training_df['FEN'].values])\n",
    "#output_data = np.array(training_df['Evaluation'].values)\n",
    "#dataset = MyDataset(input_data, output_data)\n",
    "#loader = DataLoader(dataset, batch_size = 2048, shuffle = True, num_workers = 4, pin_memory = True)\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "csv_path = '/home/yvlaere/projects/yvl-chess/NNUE_training/training_data/sf_training_data.csv'\n",
    "dataset = CsvFenScoreDataset(csv_path, shuffle_buffer=10000)\n",
    "loader = DataLoader(dataset, batch_size = 2048, num_workers = 4, pin_memory = True)\n",
    "\n",
    "# about 2.4G VRAM available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ba10ff",
   "metadata": {},
   "source": [
    "https://talkchess.com/viewtopic.php?start=60&t=75724"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e5bc53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with MAE: 7778.6611, loss: 229368960.0000\n",
      "New best model saved with MAE: 7350.9570, loss: 216233600.0000\n",
      "New best model saved with MAE: 7066.1265, loss: 210160000.0000\n",
      "New best model saved with MAE: 6929.0723, loss: 203875008.0000\n",
      "New best model saved with MAE: 6849.6157, loss: 203404608.0000\n",
      "New best model saved with MAE: 6616.1055, loss: 197880320.0000\n",
      "New best model saved with MAE: 6317.0488, loss: 188735072.0000\n",
      "New best model saved with MAE: 6239.4551, loss: 188846560.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f865d674350>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yvlaere/projects/yvl-chess/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m lowest_MAE = \u001b[32m10000\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nr_epochs):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# get data from the dataloader\u001b[39;49;00m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_y\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# move data to GPU\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/yvl-chess/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/yvl-chess/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1491\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1488\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1490\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1491\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1492\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1494\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/yvl-chess/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1443\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1441\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m   1442\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory_thread.is_alive():\n\u001b[32m-> \u001b[39m\u001b[32m1443\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1444\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1445\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/yvl-chess/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1284\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1271\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1272\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1273\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1281\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1282\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1283\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1284\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1285\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1286\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1287\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1288\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1289\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/queue.py:180\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    178\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m remaining <= \u001b[32m0.0\u001b[39m:\n\u001b[32m    179\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnot_empty\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m item = \u001b[38;5;28mself\u001b[39m._get()\n\u001b[32m    182\u001b[39m \u001b[38;5;28mself\u001b[39m.not_full.notify()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    361\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f865d674350>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yvlaere/projects/yvl-chess/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames("
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "nr_epochs = 500\n",
    "model = SimpleNNUE().to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "total_size = 200000000\n",
    "batch_size = 2048\n",
    "steps_per_epoch = total_size // batch_size\n",
    "#scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=1e-3, steps_per_epoch=steps_per_epoch, epochs=nr_epochs, pct_start=0.3, anneal_strategy='cos')\n",
    "criterion = nn.MSELoss()\n",
    "MAE_loss = nn.L1Loss()\n",
    "lowest_MAE = 10000\n",
    "\n",
    "for epoch in range(nr_epochs):\n",
    "    for batch in loader:\n",
    "        # get data from the dataloader\n",
    "        batch_x, batch_y = batch\n",
    "\n",
    "        # move data to GPU\n",
    "        batch_x = batch_x.to(device, non_blocking = True)\n",
    "        batch_y = batch_y.to(device, non_blocking = True)\n",
    "        pred = model(batch_x).squeeze(1)  # remove the last dimension\n",
    "        loss = criterion(pred, batch_y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # calculate MAE\n",
    "        MAE = MAE_loss(pred, batch_y)\n",
    "        if MAE < lowest_MAE:\n",
    "            lowest_MAE = MAE\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(f\"New best model saved with MAE: {lowest_MAE.item():.4f}, loss: {loss.item():.4f}\")\n",
    "        \n",
    "    #scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "    print(f\"Epoch {epoch+1}, MAE: {MAE.item():.4f}, lowest MAE: {lowest_MAE:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c33597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 FEN  Evaluation\n",
      "0  r1b2rk1/ppp2pbp/3q1np1/n3p1B1/2B5/1Q3N2/PP1N1P...        -135\n",
      "1  8/1pp2p2/6k1/4P2p/p1PR1K1P/2r2P2/6P1/8 w - - 0 33         -57\n",
      "2  r2qk1nr/1b3pbp/n3p1p1/1pp1P3/p2PN3/2P2N2/PPB3P...         541\n",
      "3  2b2rk1/5pp1/p2q1n1p/P2pn3/3N4/3BP1B1/2Q2PPP/Rr...         163\n",
      "4  r2qkb1r/ppp2ppb/2n1p3/3n2PQ/3Pp3/2P4P/PP6/RNB1...        -332\n",
      "18.06853701380683\n",
      "619.097853227714\n",
      "-6462\n",
      "7462\n",
      "14.0\n"
     ]
    }
   ],
   "source": [
    "input_path = '/home/yvlaere/projects/yvl-chess/NNUE_training/training_data/train.csv'\n",
    "\n",
    "training_df = pd.read_csv(input_path)\n",
    "\n",
    "print(training_df.head())\n",
    "\n",
    "print(np.mean(training_df['Evaluation']))\n",
    "print(np.std(training_df['Evaluation']))\n",
    "print(np.min(training_df['Evaluation']))\n",
    "print(np.max(training_df['Evaluation']))\n",
    "print(np.median(training_df['Evaluation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fe72d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general information on data\n",
    "input_data = np.array([FEN_to_input(fen) for fen in training_df['FEN'].values])\n",
    "output_data = np.array(training_df['Evaluation'].values)\n",
    "print(input_data.shape)\n",
    "print(output_data.shape)\n",
    "\n",
    "#1 979 383 entries\n",
    "# if converted to torch tensors, it becomes too large for the RAM (bool -> float32)\n",
    "# so it needs to be fed in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe3a6998",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import IterableDataset\n",
    "\n",
    "def get_evaluation(item):\n",
    "    if item['mate'] is not None:\n",
    "        # Assign a high positive or negative value based on the side to move\n",
    "        # Assuming positive for white mates, negative for black mates\n",
    "        return torch.tensor(10000.0 if item['mate'] > 0 else -10000.0, dtype=torch.float32)\n",
    "    elif item['cp'] is not None:\n",
    "        return torch.tensor(item['cp'], dtype=torch.float32)\n",
    "\n",
    "class ChessEvalDataset(IterableDataset):\n",
    "    def __init__(self, hf_dataset):\n",
    "        self.dataset = hf_dataset\n",
    "\n",
    "    def __iter__(self):\n",
    "        for item in self.dataset:\n",
    "            # Example: assuming \"fen\" and \"eval\" are keys\n",
    "            x = torch.tensor(FEN_to_input(item['fen']))       # Convert FEN to tensor\n",
    "            y = get_evaluation(item)  # Evaluation score\n",
    "            yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43af705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, np_input, np_output):\n",
    "        self.input = np_input\n",
    "        self.output = np_output\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.input.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # get one data point\n",
    "        np_x = self.input[idx]\n",
    "        np_y = self.output[idx]\n",
    "\n",
    "        # convert to torch tensors\n",
    "        x = torch.tensor(np_x, dtype=torch.float32)\n",
    "        y = torch.tensor(np_y, dtype=torch.float32)\n",
    "        return x, y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
