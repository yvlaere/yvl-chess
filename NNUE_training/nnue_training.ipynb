{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec5d7453",
   "metadata": {},
   "source": [
    "# NNUE training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26821225",
   "metadata": {},
   "source": [
    "## Model architecture\n",
    "\n",
    "Current model architecture is a sparse, binary array of length 768. Each element of the array represents a possible combination of piece type (6), piece_color (2) and position (64) (6*2*64 = 768).  \n",
    "\n",
    "The fully connected feedfoward network has 3 hidden layers: 768 -> 8, 8 -> 8 and 8 -> 1.\n",
    "\n",
    "The output is a single scalar.\n",
    "\n",
    "Currently used training data: test80-2024-01-jan-2tb7p.min-v2.v6.binpack.zst from https://huggingface.co/datasets/linrock/test80-2024/tree/main\n",
    "\n",
    "the stockfish tools branch has a function: stockfish convert to turn the .binpack data into .plain data\n",
    "\n",
    "Great source on NNUE: https://official-stockfish.github.io/docs/nnue-pytorch-wiki/docs/nnue.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bead68bd",
   "metadata": {},
   "source": [
    "## Input data\n",
    "### Load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b3ca347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccae3910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c33597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 FEN  Evaluation\n",
      "0  r1b2rk1/ppp2pbp/3q1np1/n3p1B1/2B5/1Q3N2/PP1N1P...        -135\n",
      "1  8/1pp2p2/6k1/4P2p/p1PR1K1P/2r2P2/6P1/8 w - - 0 33         -57\n",
      "2  r2qk1nr/1b3pbp/n3p1p1/1pp1P3/p2PN3/2P2N2/PPB3P...         541\n",
      "3  2b2rk1/5pp1/p2q1n1p/P2pn3/3N4/3BP1B1/2Q2PPP/Rr...         163\n",
      "4  r2qkb1r/ppp2ppb/2n1p3/3n2PQ/3Pp3/2P4P/PP6/RNB1...        -332\n",
      "18.06853701380683\n",
      "619.097853227714\n",
      "-6462\n",
      "7462\n",
      "14.0\n"
     ]
    }
   ],
   "source": [
    "input_path = '/home/yvlaere/projects/yvl-chess/NNUE_training/training_data/train.csv'\n",
    "\n",
    "training_df = pd.read_csv(input_path)\n",
    "\n",
    "print(training_df.head())\n",
    "\n",
    "print(np.mean(training_df['Evaluation']))\n",
    "print(np.std(training_df['Evaluation']))\n",
    "print(np.min(training_df['Evaluation']))\n",
    "print(np.max(training_df['Evaluation']))\n",
    "print(np.median(training_df['Evaluation']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ea1c61",
   "metadata": {},
   "source": [
    "### Turn FEN into input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08c3d358",
   "metadata": {},
   "outputs": [],
   "source": [
    "piece_dict = {'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5, 'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11}\n",
    "\n",
    "def FEN_to_input(fen):\n",
    "    \"\"\"\n",
    "    Convert a FEN string to an NNUE input vector.\n",
    "    \"\"\"\n",
    "    # Split the FEN string into its components\n",
    "    sub_FEN = fen.split(' ')\n",
    "    board = sub_FEN[0]\n",
    "    ranks = board.split('/')\n",
    "\n",
    "    # Convert the board to a 1D boolean array\n",
    "    # in the chess engine, position 0 corresponds to a1, so the ranks in the FEN string will need to be reversed\n",
    "    input_layer = np.zeros(768, dtype = np.float32)\n",
    "    position = 0\n",
    "    for rank in ranks[::-1]:\n",
    "        for char in rank:\n",
    "            if char.isdigit():\n",
    "                position += int(char)\n",
    "            else:\n",
    "                input_layer[position*piece_dict[char]] = 1\n",
    "\n",
    "    return input_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66f7bcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(FEN_to_input(training_df['FEN'][0]))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNNUE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNNUE, self).__init__()\n",
    "        # three fully connected layers\n",
    "        self.fc1 = nn.Linear(768, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 256)\n",
    "        self.fc3 = nn.Linear(256, 64)\n",
    "        self.fc4 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.clamp(self.fc1(x), min = 0, max = 1)\n",
    "        x = torch.clamp(self.fc2(x), min = 0, max = 1)\n",
    "        x = torch.clamp(self.fc3(x), min = 0, max = 1)\n",
    "        x = self.fc4(x)  # output can be raw score\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fe72d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general information on data\n",
    "input_data = np.array([FEN_to_input(fen) for fen in training_df['FEN'].values])\n",
    "output_data = np.array(training_df['Evaluation'].values)\n",
    "print(input_data.shape)\n",
    "print(output_data.shape)\n",
    "\n",
    "#1 979 383 entries\n",
    "# if converted to torch tensors, it becomes too large for the RAM (bool -> float32)\n",
    "# so it needs to be fed in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe3a6998",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import IterableDataset\n",
    "\n",
    "def get_evaluation(item):\n",
    "    if item['mate'] is not None:\n",
    "        # Assign a high positive or negative value based on the side to move\n",
    "        # Assuming positive for white mates, negative for black mates\n",
    "        return torch.tensor(10000.0 if item['mate'] > 0 else -10000.0, dtype=torch.float32)\n",
    "    elif item['cp'] is not None:\n",
    "        return torch.tensor(item['cp'], dtype=torch.float32)\n",
    "\n",
    "class ChessEvalDataset(IterableDataset):\n",
    "    def __init__(self, hf_dataset):\n",
    "        self.dataset = hf_dataset\n",
    "\n",
    "    def __iter__(self):\n",
    "        for item in self.dataset:\n",
    "            # Example: assuming \"fen\" and \"eval\" are keys\n",
    "            x = torch.tensor(FEN_to_input(item['fen']))       # Convert FEN to tensor\n",
    "            y = get_evaluation(item)  # Evaluation score\n",
    "            yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43af705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, np_input, np_output):\n",
    "        self.input = np_input\n",
    "        self.output = np_output\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.input.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # get one data point\n",
    "        np_x = self.input[idx]\n",
    "        np_y = self.output[idx]\n",
    "\n",
    "        # convert to torch tensors\n",
    "        x = torch.tensor(np_x, dtype=torch.float32)\n",
    "        y = torch.tensor(np_y, dtype=torch.float32)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "458f0eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yvlaere/projects/yvl-chess/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# tranport data to torch tensors\n",
    "#input_data = np.array([FEN_to_input(fen) for fen in training_df['FEN'].values])\n",
    "#output_data = np.array(training_df['Evaluation'].values)\n",
    "#dataset = MyDataset(input_data, output_data)\n",
    "#loader = DataLoader(dataset, batch_size = 2048, shuffle = True, num_workers = 4, pin_memory = True)\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "hf_dataset = load_dataset(\"Lichess/chess-position-evaluations\", split=\"train\", streaming=True)\n",
    "dataset = ChessEvalDataset(hf_dataset)\n",
    "loader = DataLoader(dataset, batch_size = 2048, num_workers = 4, pin_memory = True)\n",
    "\n",
    "# about 2.4G VRAM available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ba10ff",
   "metadata": {},
   "source": [
    "https://talkchess.com/viewtopic.php?start=60&t=75724"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e5bc53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with MAE: 1156.2480\n",
      "New best model saved with MAE: 795.2585\n",
      "New best model saved with MAE: 755.7438\n",
      "New best model saved with MAE: 719.4023\n",
      "New best model saved with MAE: 686.7310\n",
      "New best model saved with MAE: 620.8851\n",
      "New best model saved with MAE: 512.5093\n",
      "New best model saved with MAE: 508.9781\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid 83202) is killed by signal: Killed. ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch_x, batch_y \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[32m     20\u001b[39m     \u001b[38;5;66;03m# move data to GPU\u001b[39;00m\n\u001b[32m     21\u001b[39m     batch_x = batch_x.to(device, non_blocking = \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     batch_y = \u001b[43mbatch_y\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m     pred = model(batch_x).squeeze(\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# remove the last dimension\u001b[39;00m\n\u001b[32m     24\u001b[39m     loss = criterion(pred, batch_y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/yvl-chess/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/signal_handling.py:73\u001b[39m, in \u001b[36m_set_SIGCHLD_handler.<locals>.handler\u001b[39m\u001b[34m(signum, frame)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhandler\u001b[39m(signum, frame):\n\u001b[32m     71\u001b[39m     \u001b[38;5;66;03m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[32m     72\u001b[39m     \u001b[38;5;66;03m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[43m_error_if_any_worker_fails\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m previous_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     75\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(previous_handler)\n",
      "\u001b[31mRuntimeError\u001b[39m: DataLoader worker (pid 83202) is killed by signal: Killed. "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "nr_epochs = 500\n",
    "model = SimpleNNUE().to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "total_size = 581582778\n",
    "batch_size = 2048\n",
    "steps_per_epoch = total_size // batch_size\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=1e-3, \n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=nr_epochs, pct_start=0.3, \n",
    "    anneal_strategy='cos'\n",
    ")\n",
    "criterion = nn.MSELoss()\n",
    "MAE_loss = nn.L1Loss()\n",
    "lowest_MAE = 10000\n",
    "\n",
    "for epoch in range(nr_epochs):\n",
    "    for batch_x, batch_y in loader:\n",
    "        # move data to GPU\n",
    "        batch_x = batch_x.to(device, non_blocking = True)\n",
    "        batch_y = batch_y.to(device, non_blocking = True)\n",
    "        pred = model(batch_x).squeeze(1)  # remove the last dimension\n",
    "        loss = criterion(pred, batch_y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # calculate MAE\n",
    "        MAE = MAE_loss(pred, batch_y)\n",
    "        if MAE < lowest_MAE:\n",
    "            lowest_MAE = MAE\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(f\"New best model saved with MAE: {lowest_MAE.item():.4f}\")\n",
    "        \n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "    print(f\"Epoch {epoch+1}, MAE: {MAE.item():.4f}, lowest MAE: {lowest_MAE:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
