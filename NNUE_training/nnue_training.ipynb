{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec5d7453",
   "metadata": {},
   "source": [
    "# NNUE training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26821225",
   "metadata": {},
   "source": [
    "Great source on NNUE: https://official-stockfish.github.io/docs/nnue-pytorch-wiki/docs/nnue.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bead68bd",
   "metadata": {},
   "source": [
    "## Input data\n",
    "\n",
    "Stockfish has a lot of data available for NNUE training in the .binpack format. They have a repo for training NNUEs (nnue-pytorch) that enables efficient dataloading with this format, but this is not used here.\n",
    "\n",
    "The nnue-pytorch repo also has information on training datasets for NNUEs: https://github.com/official-stockfish/nnue-pytorch/wiki/Training-datasets. They explain how to make your own dataset and link some of the datasets they generated. Some of this data is used in this project, because generating the data myself would be too time-consuming on my hardware.\n",
    "\n",
    "Currently using training data: test80-2024-01-jan-2tb7p.min-v2.v6.binpack.zst from https://huggingface.co/datasets/linrock/test80-2024/tree/main\n",
    "\n",
    "This file contains billions of positions with evaluations in the .binpack format. The stockfish tools branch has a tool to covert the .binpack data into .plain data (https://github.com/official-stockfish/Stockfish/blob/tools/docs/convert.md). The first 200M evaluated positions are used here\n",
    "\n",
    "### Load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3ca347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ea1c61",
   "metadata": {},
   "source": [
    "### Turn FEN into input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129ed498",
   "metadata": {},
   "outputs": [],
   "source": [
    "piece_dict_w = {'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5, 'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11}\n",
    "piece_dict_b = {'P': 6, 'N': 7, 'B': 8, 'R': 9, 'Q': 10, 'K':11, 'p': 0, 'n': 1, 'b': 2, 'r': 3, 'q': 4, 'k': 5}\n",
    "stm_dict = {'w': 0, 'b': 1}\n",
    "\n",
    "def FEN_to_inputs(fen):\n",
    "    \"\"\"\n",
    "    Convert a FEN string to an NNUE input vector.\n",
    "    \"\"\"\n",
    "    # Split the FEN string into its components\n",
    "    sub_FEN = fen.split(' ')\n",
    "    board = sub_FEN[0]\n",
    "    ranks = board.split('/')\n",
    "    stm = stm_dict[sub_FEN[1]]\n",
    "\n",
    "    # Convert the board to a 1D boolean array\n",
    "    # in the chess engine, position 0 corresponds to a1, so the ranks in the FEN string will need to be reversed\n",
    "    input_layer_w = np.zeros(768, dtype = np.float32)\n",
    "    input_layer_b = np.zeros(768, dtype = np.float32)\n",
    "    position = 0\n",
    "    for rank in ranks[::-1]:\n",
    "        for char in rank:\n",
    "            if char.isdigit():\n",
    "                position += int(char)\n",
    "            else:\n",
    "                alt_pos = 63 - (position ^ 7)\n",
    "                input_layer_w[position + piece_dict_w[char]*64] = 1\n",
    "                input_layer_b[alt_pos + piece_dict_b[char]*64] = 1\n",
    "                position += 1\n",
    "\n",
    "    return torch.tensor(input_layer_w, dtype=torch.float32), torch.tensor(input_layer_b, dtype=torch.float32), torch.tensor(stm, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1938bf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing encoding\n",
    "fen1 = 'rnbqkbnr/pppppppp/8/8/8/5P2/PPPPP1PP/RNBQKBNR b KQkq - 0 1'\n",
    "\n",
    "w_features, b_features, stm = FEN_to_inputs(fen1)\n",
    "print(\"White Features:\", sum(w_features))\n",
    "print(np.nonzero(np.array(w_features)))\n",
    "print(\"Black Features:\", sum(b_features))\n",
    "print(np.nonzero(np.array(b_features)))\n",
    "print(\"Side to Move:\", stm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cdf67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = [192, 65, 130, 259, 324, 133, 70, 199, 8, 9, 10, 11, 12, 14, 15, 21, 432, 433, 434, 435, 436, 437, 438, 439, 632, 505, 570, 699, 764, 573, 510, 639]\n",
    "test2 = [ 8, 9,  10,  11,  12,  14,  15,  21,  65,  70, 130, 133, 192, 199, 259, 324, 432, 433, 434, 435, 436, 437, 438, 439, 505, 510, 570, 573, 632, 639, 699, 764]\n",
    "\n",
    "np.sort(test1)\n",
    "np.sort(test2)\n",
    "print(np.array_equal(np.sort(test1), np.sort(test2)))\n",
    "\n",
    "test3 = [  8,   9,  10,  11,  12,  13,  14,  15,  65,  70, 130, 133, 192, 199, 259, 324, 429, 432, 433, 434, 435, 436, 438, 439, 505, 510,  570, 573, 632, 639, 699, 764]\n",
    "test4 = [632, 505, 570, 699, 764, 573, 510, 639, 432, 433, 434, 435, 436, 438, 439, 429, 8, 9, 10, 11, 12, 13, 14, 15, 192, 65, 130, 259, 324, 133, 70, 199]\n",
    "print(np.array_equal(np.sort(test3), np.sort(test4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429c0263",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01de9504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Split_NNUE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Split_NNUE, self).__init__()\n",
    "        self.fc1 = nn.Linear(768, 128)\n",
    "        self.fc2 = nn.Linear(256, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, white_features, black_features, stm):\n",
    "        w = self.fc1(white_features)\n",
    "        b = self.fc1(black_features)\n",
    "        cat_wb = torch.cat([w, b], dim=1)\n",
    "        cat_bw = torch.cat([b, w], dim=1)\n",
    "\n",
    "        stm = stm.to(dtype=cat_wb.dtype).view(-1, 1)\n",
    "\n",
    "        accumulator = (1 - stm) * cat_wb + stm * cat_bw\n",
    "\n",
    "        x = torch.clamp(accumulator, min = 0, max = 1)\n",
    "        x = torch.clamp(self.fc2(x), min = 0, max = 1)\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f32318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import torch\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "\n",
    "class Custom_Split_Dataset(IterableDataset):\n",
    "    def __init__(self, csv_path, shuffle_buffer=0):\n",
    "        \"\"\"\n",
    "        csv_path: path to CSV file with two columns: fen, score\n",
    "        fen_to_tensor: function(str) -> torch.Tensor\n",
    "        shuffle_buffer: size of in-memory shuffle buffer; 0 = no shuffle\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.csv_path = csv_path\n",
    "        self.shuffle_buffer = shuffle_buffer\n",
    "\n",
    "    def _row_stream(self):\n",
    "        \"\"\"\n",
    "        Generator that yields (fen, score) tuples from the CSV file.\n",
    "        \"\"\"\n",
    "        with open(self.csv_path, newline='') as csvfile:\n",
    "            reader = csv.reader(csvfile)\n",
    "            for row in reader:\n",
    "                if not row or row[0].startswith('#'):\n",
    "                    continue\n",
    "                w_in, b_in, stm = FEN_to_inputs(row[0].strip())\n",
    "                score, result = float(row[1].strip()), float(row[2].strip())\n",
    "                if score == 32002:\n",
    "                    score = 0\n",
    "                if result == -1:\n",
    "                    result = 0\n",
    "                elif result == 0:\n",
    "                    result = 0.5\n",
    "                yield w_in, b_in, stm, torch.tensor(score, dtype=torch.float32), torch.tensor(result, dtype=torch.float32)\n",
    "\n",
    "    def __iter__(self):\n",
    "        stream = self._row_stream()\n",
    "        if self.shuffle_buffer > 1:\n",
    "\n",
    "            # reservoir-style shuffle buffer\n",
    "            buf = []\n",
    "            for w_in, b_in, stm, score, result in stream:\n",
    "                buf.append((w_in, b_in, stm, score, result))\n",
    "                if len(buf) >= self.shuffle_buffer:\n",
    "                    idx = torch.randint(len(buf), (1,)).item()\n",
    "                    yield buf.pop(idx)\n",
    "                    \n",
    "            # drain remaining buffer\n",
    "            while buf:\n",
    "                idx = torch.randint(len(buf), (1,)).item()\n",
    "                yield buf.pop(idx)\n",
    "        else:\n",
    "            for w_in, b_in, stm, score, result in stream:\n",
    "                yield w_in, b_in, stm, score, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458f0eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load the dataset\n",
    "csv_path = '/home/yvlaere/projects/yvl-chess/NNUE_training/training_data/sf_training_data_full.csv'\n",
    "dataset = Custom_Split_Dataset(csv_path, shuffle_buffer = 100000)\n",
    "loader = DataLoader(dataset, batch_size = 1024, num_workers = 4, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa7cc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        # Kaiming uniform for piecewise-linear (ReLU-like) activations:\n",
    "        nn.init.kaiming_uniform_(m.weight, a=0.0, nonlinearity='relu')\n",
    "        nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5bc53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir=\"runs/nnue_training_split_model_200M_6_\")\n",
    "\n",
    "# hyperparameters\n",
    "nr_epochs = 10000\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-5\n",
    "scaling_factor = 400\n",
    "ground_truth_scaling_factor = 400\n",
    "lambda_ = 0.2\n",
    "log_interval = 100\n",
    "save_interval = 100000\n",
    "step = 0\n",
    "running_loss = 0.0\n",
    "epsilon = 1e-10\n",
    "\n",
    "# initialize model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Split_NNUE()\n",
    "checkpoint = torch.load('saved_models/split_model_200M_5_18600000.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model = model.to(device)\n",
    "#model.apply(init_weights)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = learning_rate, weight_decay = weight_decay)\n",
    "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=100, min_lr=1e-6)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1000000, gamma=0.5)\n",
    "criterion = nn.MSELoss()\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for epoch in range(nr_epochs):\n",
    "    for batch in loader:\n",
    "\n",
    "        #for _ in range(1000000):\n",
    "    \n",
    "        # get data from the dataloader\n",
    "        batch_x_w, batch_x_b, stm, batch_y, result = batch\n",
    "        batch_x_w = batch_x_w.to(device, non_blocking = True)\n",
    "        batch_x_b = batch_x_b.to(device, non_blocking = True)\n",
    "        stm = stm.to(device, non_blocking = True)\n",
    "        batch_y = batch_y.to(device, non_blocking = True)\n",
    "        result = result.to(device, non_blocking = True)\n",
    "        pred = model(batch_x_w, batch_x_b, stm).squeeze(1)\n",
    "\n",
    "        # Transform the CP scores to the WDL space\n",
    "        wdl_batch_y = lambda_*result + (1 - lambda_) * torch.sigmoid(batch_y / ground_truth_scaling_factor)\n",
    "        wdl_pred = torch.sigmoid(pred / scaling_factor)\n",
    "\n",
    "        #loss = (wdl_batch_y * torch.log(wdl_batch_y + epsilon) + (1 - wdl_batch_y) * torch.log(1 - wdl_batch_y + epsilon)) -(wdl_batch_y * torch.log(wdl_pred   + epsilon) + (1 - wdl_batch_y) * torch.log(1 - wdl_pred   + epsilon))\n",
    "        #loss = loss.mean()\n",
    "\n",
    "        # calculate the loss\n",
    "        loss = criterion(wdl_pred, wdl_batch_y)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # make a step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #scheduler.step()\n",
    "        step += 1\n",
    "\n",
    "        # calculate the gradient norm\n",
    "        total_norm_sq = 0.0\n",
    "        for p in model.parameters():\n",
    "            if p.grad is not None:\n",
    "                param_norm = p.grad.data.norm(2)  # L2 norm of this parameter's gradient\n",
    "                total_norm_sq += param_norm.item() ** 2\n",
    "        total_grad_norm = total_norm_sq ** 0.5\n",
    "        # Now total_grad_norm is the L2 norm of all gradients combined.\n",
    "        #print(f\"Step {step}  Grad Norm = {total_grad_norm:.8f}\")\n",
    "\n",
    "        # Log every `log_interval` steps\n",
    "        if step % log_interval == 0 and step != 0:\n",
    "            avg_loss = running_loss / log_interval\n",
    "            print(f\"Epoch {epoch+1} | Step {step} | Avg Loss: {avg_loss:.4f} | Grad Norm: {total_grad_norm:.8f}\")\n",
    "            running_loss = 0.0\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            writer.add_scalar(\"Loss/train\", avg_loss, step)\n",
    "            writer.add_scalar(\"LR\", current_lr, step)\n",
    "            writer.add_scalar(\"Grad Norm\", total_grad_norm, step)\n",
    "            writer.add_scalar(\"WDL Pred\", torch.mean(wdl_pred).item(), step)\n",
    "            writer.add_scalar(\"WDL BatchY\", torch.mean(wdl_batch_y).item(), step)\n",
    "            writer.add_scalar(\"Pred\", torch.median(pred).item(), step)\n",
    "            writer.add_scalar(\"BatchY\", torch.median(batch_y).item(), step)\n",
    "\n",
    "\n",
    "            # log separate grad norms\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.grad is not None:\n",
    "                    grad_norm = param.grad.data.norm(2).item()\n",
    "                    writer.add_scalar(f'GradNorm/{name}', grad_norm, step)\n",
    "\n",
    "        # Save the model every `save_interval` steps\n",
    "        if step % save_interval == 0:\n",
    "            model_name = 'saved_models/split_model_200M_6_' + str(step) + \".pth\"\n",
    "            print(\"Saving model at step\" + str(step))\n",
    "            torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,}, model_name)\n",
    "            \n",
    "    #scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d17d09a",
   "metadata": {},
   "source": [
    "### Postprocessing of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede75645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the model to be read by the chess engine\n",
    "model = Split_NNUE()\n",
    "checkpoint = torch.load('saved_models/split_model_200M_6_4300000.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "def save_layer(layer, name):\n",
    "    w = layer.weight.detach().numpy()\n",
    "    b = layer.bias.detach().numpy()\n",
    "    with open(f\"{name}_weights.txt\", \"w\") as f:\n",
    "        for row in w:\n",
    "            f.write(\" \".join(map(str, row)) + \"\\n\")\n",
    "    with open(f\"{name}_biases.txt\", \"w\") as f:\n",
    "        f.write(\" \".join(map(str, b)))\n",
    "\n",
    "save_layer(model.fc1, \"model/layer1\")\n",
    "save_layer(model.fc2, \"model/layer2\")\n",
    "save_layer(model.fc3, \"model/layer3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f8086a",
   "metadata": {},
   "source": [
    "### Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22e35ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Split_NNUE()\n",
    "checkpoint = torch.load('saved_models/split_model_10M_100000.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "model.eval()\n",
    "fen1 = 'rnbqkbnr/pppppppp/8/8/8/5P2/PPPPP1PP/RNBQKBNR b KQkq - 0 1'\n",
    "fen2 = 'rnbqkbnr/pppppppp/8/8/8/7N/PPPPPPPP/RNBQKB1R b KQkq - 1 1'\n",
    "fen3 = 'rnbqkbnr/pppppppp/8/8/8/5N2/PPPPPPPP/RNBQKB1R b KQkq - 1 1'\n",
    "\n",
    "start_fen = 'rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1'\n",
    "\n",
    "#torch.tensor(FEN_to_input(fen1))\n",
    "\n",
    "with torch.no_grad():\n",
    "    w1, b1, stm1 = FEN_to_inputs(fen1)\n",
    "    w1 = w1.unsqueeze(0)\n",
    "    b1 = b1.unsqueeze(0)\n",
    "    stm1 = stm1.unsqueeze(0)\n",
    "    print(w1.shape, b1.shape, stm1.shape)\n",
    "    #in_1 = np.argwhere(input1.numpy() == 1)\n",
    "    #print(sum(input1.numpy()))\n",
    "    w2, b2, stm2 = FEN_to_inputs(fen2)\n",
    "    w2 = w2.unsqueeze(0)\n",
    "    b2 = b2.unsqueeze(0)\n",
    "    stm2 = stm2.unsqueeze(0)\n",
    "    #print(np.argwhere(input2.numpy() == 1))\n",
    "    w3, b3, stm3 = FEN_to_inputs(fen3)\n",
    "    w3 = w3.unsqueeze(0)\n",
    "    b3 = b3.unsqueeze(0)\n",
    "    stm3 = stm3.unsqueeze(0)\n",
    "    #print(np.argwhere(input3.numpy() == 1))\n",
    "\n",
    "    #in_start = np.argwhere(FEN_to_inputs(start_fen).numpy() == 1)\n",
    "\n",
    "    pred1 = model(w1, b1, stm1)\n",
    "    pred2 = model(w2, b2, stm2)\n",
    "    pred3 = model(w3, b3, stm3)\n",
    "\n",
    "    print(pred1.item())\n",
    "    print(pred2.item())\n",
    "    print(pred3.item())\n",
    "\n",
    "    #accumulator = model.fc1(input1)\n",
    "    #ws, bs, stms = FEN_to_inputs(start_fen)\n",
    "    #ws = ws.unsqueeze(0)\n",
    "    #bs = bs.unsqueeze(0)\n",
    "    #stms = stms.unsqueeze(0)\n",
    "    w_accumulator = model.fc1(w1)\n",
    "    b_accumulator = model.fc1(b1)\n",
    "    #print(w_accumulator)\n",
    "    #print(b_accumulator)\n",
    "\n",
    "\n",
    "    cat_wb = torch.cat([w_accumulator, b_accumulator], dim=1)\n",
    "    cat_bw = torch.cat([b_accumulator, w_accumulator], dim=1)\n",
    "\n",
    "    #stm1 = stm1.to(dtype=cat_wb.dtype).view(-1, 1)\n",
    "    #print(cat_bw)\n",
    "\n",
    "    accumulator = (1 - stm1) * cat_wb + stm1 * cat_bw\n",
    "    #print(accumulator)\n",
    "\n",
    "    x = torch.clamp(accumulator, min = 0, max = 1)\n",
    "    x = model.fc2(x)\n",
    "\n",
    "    #print(x)\n",
    "\n",
    "    print(model.fc2.bias.detach().numpy())\n",
    "    #print(model.fc2.weight[0][:10])\n",
    "\n",
    "    #print(\"weights[0][0]\")\n",
    "    #print(model.fc1.weight[0][0])\n",
    "    #print(\"weights[1][0]\")\n",
    "    #print(model.fc1.weight[1][0])\n",
    "    #print(model.fc1.bias[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df76abc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set number of bins\n",
    "num_bins = 64\n",
    "bin_edges = np.linspace(-32003, 32003, num_bins + 1)\n",
    "counts = np.zeros(num_bins, dtype=int)\n",
    "\n",
    "filename = '/home/yvlaere/projects/yvl-chess/NNUE_training/training_data/scores.txt'\n",
    "\n",
    "# Re-read the file and bin values\n",
    "with open(filename, 'r') as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            val = float(line.strip())\n",
    "            # Determine bin index\n",
    "            bin_idx = np.searchsorted(bin_edges, val, side='right') - 1\n",
    "            if 0 <= bin_idx < num_bins:\n",
    "                counts[bin_idx] += 1\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "# Find empty bins\n",
    "empty_bins = []\n",
    "for i, count in enumerate(counts):\n",
    "    if count == 0:\n",
    "        left_edge = bin_edges[i]\n",
    "        right_edge = bin_edges[i + 1]\n",
    "        empty_bins.append((i, left_edge, right_edge))\n",
    "\n",
    "# Print empty bin ranges\n",
    "print(\"Empty bins:\")\n",
    "for i, left, right in empty_bins:\n",
    "    print(f\"Bin {i}: [{left}, {right})\")\n",
    "\n",
    "# Plot histogram\n",
    "plt.bar(bin_edges[:-1], counts, width=np.diff(bin_edges), edgecolor='black', align='edge')\n",
    "plt.title(\"Histogram (streamed)\")\n",
    "plt.xlabel(\"Scores\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2a4684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CP to WDL conversion\n",
    "scaling_factor = 400\n",
    "score = torch.tensor(32000, dtype=torch.float32)\n",
    "print(torch.sigmoid(score / scaling_factor))\n",
    "score = torch.tensor(1000, dtype=torch.float32)\n",
    "print(torch.sigmoid(score / scaling_factor))\n",
    "score = torch.tensor(-1000, dtype=torch.float32)\n",
    "print(torch.sigmoid(score / scaling_factor))\n",
    "score = torch.tensor(0, dtype=torch.float32)\n",
    "print(torch.sigmoid(score / scaling_factor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f41259",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_2 = [192, 65, 130, 259, 324, 133, 70, 199, 8, 9, 10, 11, 12, 13, 14, 15, 432, 433, 434, 435, 436, 437, 438, 439, 632, 505, 570, 699, 764, 573, 510, 639]\n",
    "\n",
    "print(np.sort(in_start.reshape(1, 32)))\n",
    "print(np.sort(in_2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b481ab8",
   "metadata": {},
   "source": [
    "### HalfKP (not currently used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9132a3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "piece_dict = {'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5, 'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11}\n",
    "stm_dict = {'w': 0, 'b': 1}\n",
    "\n",
    "\n",
    "def FEN_to_HalfKP(fen):\n",
    "    \"\"\"\n",
    "    Convert a FEN string to an NNUE input vector.\n",
    "    \"\"\"\n",
    "    # Split the FEN string into its components\n",
    "    sub_FEN = fen.split(' ')\n",
    "    board = sub_FEN[0]\n",
    "    stm = stm_dict[sub_FEN[1]]\n",
    "    ranks = board.split('/')\n",
    "\n",
    "    # Convert the board to a 1D boolean array\n",
    "    # in the chess engine, position 0 corresponds to a1, so the ranks in the FEN string will need to be reversed\n",
    "    input_layer = np.zeros(40960, dtype = np.float32)\n",
    "    position = 0\n",
    "    white_king_position = 0\n",
    "    black_king_position = 0\n",
    "    for rank in ranks[::-1]:\n",
    "        for char in rank:\n",
    "            if char.isdigit():\n",
    "                position += int(char)\n",
    "            elif char == 'K':\n",
    "                white_king_position = position\n",
    "                position += 1\n",
    "            elif char == 'k':\n",
    "                black_king_position = position\n",
    "                position += 1\n",
    "            else:\n",
    "                position += 1\n",
    "\n",
    "    white_input_layer = np.zeros(40960, dtype = np.float32)\n",
    "    black_input_layer = np.zeros(40960, dtype = np.float32)\n",
    "\n",
    "    position = 0\n",
    "    for rank in ranks[::-1]:\n",
    "        for char in rank:\n",
    "            if char.isdigit():\n",
    "                position += int(char)\n",
    "            else:\n",
    "                if (char != 'K') & (char != 'k'):\n",
    "                    piece_index = (piece_dict[char] % 6) * 2 + (piece_dict[char] > 5)\n",
    "                    white_input_layer[position + (piece_index + white_king_position*10)*64] = 1\n",
    "                    black_input_layer[position + (piece_index + black_king_position*10)*64] = 1\n",
    "                    position += 1\n",
    "                else:\n",
    "                    position += 1\n",
    "\n",
    "    return torch.tensor(white_input_layer, dtype=torch.float32), torch.tensor(black_input_layer, dtype=torch.float32), torch.tensor(stm, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6378bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import torch\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "\n",
    "class HalfKP_Dataset(IterableDataset):\n",
    "    def __init__(self, csv_path, shuffle_buffer=0):\n",
    "        \"\"\"\n",
    "        csv_path: path to CSV file with two columns: fen, score\n",
    "        fen_to_tensor: function(str) -> torch.Tensor\n",
    "        shuffle_buffer: size of in-memory shuffle buffer; 0 = no shuffle\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.csv_path = csv_path\n",
    "        self.shuffle_buffer = shuffle_buffer\n",
    "\n",
    "    def _row_stream(self):\n",
    "        \"\"\"\n",
    "        Generator that yields (fen, score) tuples from the CSV file.\n",
    "        \"\"\"\n",
    "        with open(self.csv_path, newline='') as csvfile:\n",
    "            reader = csv.reader(csvfile)\n",
    "            for row in reader:\n",
    "                if not row or row[0].startswith('#'):\n",
    "                    continue\n",
    "                w_in, b_in, stm = FEN_to_HalfKP(row[0].strip())\n",
    "                score = float(row[1].strip())\n",
    "                if score == 32002:\n",
    "                    score = 0\n",
    "                yield w_in, b_in, stm, torch.tensor(score, dtype=torch.float32)\n",
    "\n",
    "    def __iter__(self):\n",
    "        stream = self._row_stream()\n",
    "        if self.shuffle_buffer > 1:\n",
    "\n",
    "            # reservoir-style shuffle buffer\n",
    "            buf = []\n",
    "            for w_in, b_in, stm, score in stream:\n",
    "                buf.append((w_in, b_in, stm, score))\n",
    "                if len(buf) >= self.shuffle_buffer:\n",
    "                    idx = torch.randint(len(buf), (1,)).item()\n",
    "                    yield buf.pop(idx)\n",
    "                    \n",
    "            # drain remaining buffer\n",
    "            while buf:\n",
    "                idx = torch.randint(len(buf), (1,)).item()\n",
    "                yield buf.pop(idx)\n",
    "        else:\n",
    "            for w_in, b_in, stm, score in stream:\n",
    "                yield w_in, b_in, stm, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba8c6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "NUM_FEATURES = 40960\n",
    "M = 1024\n",
    "N = 32\n",
    "K = 1\n",
    "\n",
    "class HalfKPNNUE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HalfKPNNUE, self).__init__()\n",
    "        # three fully connected layers\n",
    "        self.fc1 = nn.Linear(NUM_FEATURES, M)\n",
    "        self.fc2 = nn.Linear(2*M, N)\n",
    "        self.fc3 = nn.Linear(N, K)\n",
    "\n",
    "    def forward(self, white_features, black_features, stm):\n",
    "        w = self.fc1(white_features)\n",
    "        b = self.fc1(black_features)\n",
    "        cat_wb = torch.cat([w, b], dim=1)  # [B, 2*M]\n",
    "        cat_bw = torch.cat([b, w], dim=1)  # [B, 2*M]\n",
    "\n",
    "        stm = stm.to(dtype=cat_wb.dtype).view(-1, 1)\n",
    "\n",
    "        accumulator = stm * cat_wb + (1 - stm) * cat_bw\n",
    "\n",
    "        x = torch.clamp(accumulator, min = 0.0, max = 1.0)\n",
    "        x = torch.clamp(self.fc2(x), min = 0, max = 1)\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4456a1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load the dataset\n",
    "csv_path = '/home/yvlaere/projects/yvl-chess/NNUE_training/training_data/sf_training_data.csv'\n",
    "dataset = HalfKP_Dataset(csv_path, shuffle_buffer=1000)\n",
    "loader = DataLoader(dataset, batch_size = 128, num_workers = 4, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afce15f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir=\"runs/halfKP\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "nr_epochs = 500\n",
    "model = HalfKPNNUE().to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.1, weight_decay=1e-4)\n",
    "#optimizer = torch.optim.Adadelta(model.parameters(), lr = 0.05)\n",
    "total_size = 200000000\n",
    "batch_size = 128\n",
    "steps_per_epoch = total_size // batch_size\n",
    "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=100, min_lr=1e-6)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 100000, gamma=0.5)\n",
    "criterion = nn.MSELoss()\n",
    "MAE_loss = nn.L1Loss()\n",
    "lowest_MAE = 10000\n",
    "\n",
    "# Transform the CP scores to the WDL space\n",
    "scaling_factor = 400\n",
    "\n",
    "running_loss = 0.0\n",
    "running_mae = 0.0\n",
    "log_interval = 100\n",
    "step = 0\n",
    "\n",
    "for epoch in range(nr_epochs):\n",
    "    for batch in loader:\n",
    "        #for _ in range(100000):\n",
    "\n",
    "        # get data from the dataloader\n",
    "        batch_x_w, batch_x_b, stm, batch_y = batch\n",
    "\n",
    "        # move data to GPU\n",
    "        batch_x_w = batch_x_w.to(device, non_blocking = True)\n",
    "        batch_x_b = batch_x_b.to(device, non_blocking = True)\n",
    "        batch_y = batch_y.to(device, non_blocking = True)\n",
    "        stm = stm.to(device, non_blocking = True)\n",
    "        pred = model(batch_x_w, batch_x_b, stm).squeeze(1)  # remove the last dimension\n",
    "\n",
    "        # Transform the CP scores to the WDL space\n",
    "        wdl_batch_y = torch.sigmoid(batch_y / scaling_factor)\n",
    "        wdl_pred = torch.sigmoid(pred / scaling_factor)\n",
    "\n",
    "        # calculate the MSE loss\n",
    "        loss = criterion(wdl_batch_y, wdl_pred)\n",
    "        MAE = MAE_loss(wdl_batch_y, wdl_pred)\n",
    "        running_loss += loss.item()\n",
    "        running_mae += MAE\n",
    "        step += 1\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        \n",
    "\n",
    "        # Log every `log_interval` steps\n",
    "        if step % log_interval == 0 and step != 0:\n",
    "            avg_loss = running_loss / log_interval\n",
    "            avg_mae = running_mae / log_interval\n",
    "            print(f\"Epoch {epoch+1} | Step {step}/{steps_per_epoch} | Avg Loss: {avg_loss:.4f}\")\n",
    "            running_loss = 0.0\n",
    "            running_mae = 0\n",
    "            writer.add_scalar(\"Loss/train\", avg_loss, step)\n",
    "            writer.add_scalar(\"MAE/train\", avg_mae, step)\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            writer.add_scalar(\"LR\", current_lr, step)\n",
    "\n",
    "        # calculate MAE\n",
    "        if MAE < 0.0002:\n",
    "            lowest_MAE = MAE\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(f\"New best model saved with MAE: {lowest_MAE.item():.4f}, loss: {loss.item():.4f}\")\n",
    "    \n",
    "    #scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "    print(f\"Epoch {epoch+1}, MAE: {MAE.item():.4f}, lowest MAE: {lowest_MAE:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aab032d",
   "metadata": {},
   "outputs": [],
   "source": [
    "piece_dict = {'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5, 'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11}\n",
    "\n",
    "def FEN_to_input(fen):\n",
    "    \"\"\"\n",
    "    Convert a FEN string to an NNUE input vector.\n",
    "    \"\"\"\n",
    "    # Split the FEN string into its components\n",
    "    sub_FEN = fen.split(' ')\n",
    "    board = sub_FEN[0]\n",
    "    ranks = board.split('/')\n",
    "\n",
    "    # Convert the board to a 1D boolean array\n",
    "    # in the chess engine, position 0 corresponds to a1, so the ranks in the FEN string will need to be reversed\n",
    "    input_layer = np.zeros(768, dtype = np.float32)\n",
    "    position = 0\n",
    "    for rank in ranks[::-1]:\n",
    "        for char in rank:\n",
    "            if char.isdigit():\n",
    "                position += int(char)\n",
    "            else:\n",
    "                input_layer[position + piece_dict[char]*64] = 1\n",
    "                position += 1\n",
    "\n",
    "    return torch.tensor(input_layer, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd47b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNNUE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNNUE, self).__init__()\n",
    "        # three fully connected layers\n",
    "        self.fc1 = nn.Linear(768, 256)\n",
    "        self.fc2 = nn.Linear(256, 32)\n",
    "        #self.fc3 = nn.Linear(128, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = torch.clamp(self.fc1(x), min = 0, max = 1)\n",
    "        #x = torch.clamp(self.fc2(x), min = 0, max = 1)\n",
    "        #x = torch.clamp(self.fc3(x), min = 0, max = 1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        #x = self.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e9f45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import torch\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "\n",
    "class Custom_Dataset(IterableDataset):\n",
    "    def __init__(self, csv_path, shuffle_buffer=0):\n",
    "        \"\"\"\n",
    "        csv_path: path to CSV file with two columns: fen, score\n",
    "        fen_to_tensor: function(str) -> torch.Tensor\n",
    "        shuffle_buffer: size of in-memory shuffle buffer; 0 = no shuffle\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.csv_path = csv_path\n",
    "        self.shuffle_buffer = shuffle_buffer\n",
    "\n",
    "    def _row_stream(self):\n",
    "        \"\"\"\n",
    "        Generator that yields (fen, score) tuples from the CSV file.\n",
    "        \"\"\"\n",
    "        with open(self.csv_path, newline='') as csvfile:\n",
    "            reader = csv.reader(csvfile)\n",
    "            for row in reader:\n",
    "                if not row or row[0].startswith('#'):\n",
    "                    continue\n",
    "                fen, score, result = FEN_to_input(row[0].strip()), float(row[1].strip()), float(row[2].strip())\n",
    "                if score == 32002:\n",
    "                    score = 0\n",
    "                if result == -1:\n",
    "                    result = 0\n",
    "                elif result == 0:\n",
    "                    result = 0.5\n",
    "                yield fen, torch.tensor(score, dtype=torch.float32), torch.tensor(result, dtype=torch.float32)\n",
    "\n",
    "    def __iter__(self):\n",
    "        stream = self._row_stream()\n",
    "        if self.shuffle_buffer > 1:\n",
    "\n",
    "            # reservoir-style shuffle buffer\n",
    "            buf = []\n",
    "            for fen, score, result in stream:\n",
    "                buf.append((fen, score, result))\n",
    "                if len(buf) >= self.shuffle_buffer:\n",
    "                    idx = torch.randint(len(buf), (1,)).item()\n",
    "                    yield buf.pop(idx)\n",
    "                    \n",
    "            # drain remaining buffer\n",
    "            while buf:\n",
    "                idx = torch.randint(len(buf), (1,)).item()\n",
    "                yield buf.pop(idx)\n",
    "        else:\n",
    "            for fen, score, result in stream:\n",
    "                yield fen, score, result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
